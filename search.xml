<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>详解@RequestParam</title>
      <link href="/posts/f43726f7/"/>
      <url>/posts/f43726f7/</url>
      
        <content type="html"><![CDATA[<h3 id="RequestParam"><a href="#RequestParam" class="headerlink" title="@RequestParam"></a>@RequestParam</h3><p>在Java中，<code>@RequestParam</code> 是一个注解，用于从HTTP请求中获取参数值。它通常用于Spring MVC框架中的控制器方法中，以指定方法参数应该绑定到HTTP请求中的特定参数。</p><p><code>@RequestParam</code> 可以用于处理HTTP请求的查询参数、表单参数或路径参数。它可以应用于方法的参数或方法的参数上的注解。</p><p>下面是一些示例：</p><ol><li>使用默认参数名称：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/example&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">exampleMethod</span><span class="params">(<span class="meta">@RequestParam</span> String param)</span> &#123;</span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码将尝试从HTTP请求中获取名为 “param” 的查询参数，并将其绑定到方法参数 <code>param</code>。</p><ol start="2"><li>使用自定义参数名称：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/example&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">exampleMethod</span><span class="params">(<span class="meta">@RequestParam(&quot;customParam&quot;)</span> String param)</span> &#123;</span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个示例中，<code>@RequestParam</code> 注解指定了参数的自定义名称 “customParam”，它将从HTTP请求中获取该参数，并将其绑定到方法参数 <code>param</code>。</p><ol start="3"><li>设置默认值：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/example&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">exampleMethod</span><span class="params">(<span class="meta">@RequestParam(value = &quot;param&quot;, defaultValue = &quot;default&quot;)</span> String param)</span> &#123;</span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个示例中，如果请求中没有名为 “param” 的参数，或者参数的值为空，那么方法参数 <code>param</code> 将被设置为默认值 “default”。</p><ol start="4"><li>必需的参数：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/example&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">exampleMethod</span><span class="params">(<span class="meta">@RequestParam(required = true)</span> String param)</span> &#123;</span><br><span class="line">    <span class="comment">// 方法体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个示例中，<code>@RequestParam</code> 注解的 <code>required</code> 属性被设置为 <code>true</code>，表示参数是必需的。如果请求中没有提供该参数，将会返回错误。</p><p>总结一下，<code>@RequestParam</code> 注解用于从HTTP请求中获取参数值，并将其绑定到Java方法的参数。它提供了许多选项，可以根据需要配置参数的名称、默认值和是否必需。这样，开发者可以方便地处理HTTP请求中的参数。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cesium面试题</title>
      <link href="/posts/a98e3ede/"/>
      <url>/posts/a98e3ede/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/img_convert/e0239a75f96830e577eef736ebcad965.png" alt="img"></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h1 id="Cesium开发面试题"><a href="#Cesium开发面试题" class="headerlink" title="Cesium开发面试题"></a>Cesium开发面试题</h1><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><h2 id="1、请简要介绍一下Cesium的基本功能。"><a href="#1、请简要介绍一下Cesium的基本功能。" class="headerlink" title="1、请简要介绍一下Cesium的基本功能。"></a>1、请简要介绍一下Cesium的基本功能。</h2><p>答：Cesium是一款3D地球可视化引擎，可以在Web浏览器中显示高度真实感的3D地球场景，包括地形、地表纹理、3D建筑、水域等。它提供多种漫游和导航方式，支持多种地形和影像数据格式，以及3D Tiles、CZML等技术，可以用于实时位置追踪、天文数据显示、地下和空中场景等应用场景。</p><h2 id="2、请解释一下Cesium中的3D-Tiles技术是什么，以及它的作用是什么。"><a href="#2、请解释一下Cesium中的3D-Tiles技术是什么，以及它的作用是什么。" class="headerlink" title="2、请解释一下Cesium中的3D Tiles技术是什么，以及它的作用是什么。"></a>2、请解释一下Cesium中的3D Tiles技术是什么，以及它的作用是什么。</h2><p>  答：3D Tiles是一种用于高效地加载和显示大规模的3D地球数据的技术，可以将复杂的3D数据分层并进行高度优化。Cesium中的3D Tiles技术可以支持大规模的3D地球数据，包括城市、建筑、地形等，提高了数据的加载速度和显示效率。</p><h2 id="3、CZML是Cesium中的一个数据格式，它是什么，以及它用于描述什么样的场景？"><a href="#3、CZML是Cesium中的一个数据格式，它是什么，以及它用于描述什么样的场景？" class="headerlink" title="3、CZML是Cesium中的一个数据格式，它是什么，以及它用于描述什么样的场景？"></a>3、CZML是Cesium中的一个数据格式，它是什么，以及它用于描述什么样的场景？</h2><p>  答：CZML（Cesium Language）是一种描述和显示动态的地球场景的数据格式，它可以用于描述航班轨迹、气象数据、卫星运行轨迹等。CZML中可以包含实体的位置、速度、方向等信息，以及可视化效果的设置。</p><h2 id="4、请解释一下Cesium中的ImageryProvider是什么，以及它的作用是什么。"><a href="#4、请解释一下Cesium中的ImageryProvider是什么，以及它的作用是什么。" class="headerlink" title="4、请解释一下Cesium中的ImageryProvider是什么，以及它的作用是什么。"></a>4、请解释一下Cesium中的ImageryProvider是什么，以及它的作用是什么。</h2><p>  答：ImageryProvider是Cesium中的一个数据提供器，用于提供地图和影像数据。它可以从多种来源获取数据，比如Web Map Service（WMS）、Web Map Tile Service（WMTS）等，并在地球表面上显示出来。通过使用ImageryProvider，开发者可以轻松地获取并显示各种地图和影像数据。</p><h2 id="5、如何加载飞线"><a href="#5、如何加载飞线" class="headerlink" title="5、如何加载飞线"></a>5、如何加载飞线</h2><p>  答：1、创建polyLine实体</p><p>   2、计算带有弧度效果的点集数组作为polyline的positions属性参数</p><h2 id="6、如何设置飞线动效材质"><a href="#6、如何设置飞线动效材质" class="headerlink" title="6、如何设置飞线动效材质"></a>6、如何设置飞线动效材质</h2><p>答：1、创建cesium自定义材质类</p><p>2、创建shader，原理是通过贴图UV移动来实现流光效果</p><h2 id="7、如何在cesium地球上添加柱状图"><a href="#7、如何在cesium地球上添加柱状图" class="headerlink" title="7、如何在cesium地球上添加柱状图"></a>7、如何在cesium地球上添加柱状图</h2><p>答：1、创建entity实体，使用box属性；</p><p>2、dimensions设置长宽；</p><p>3、position设置中心点位置；</p><p>4、heightReference属性设置贴地属性；</p><h2 id="8、如何让柱状图跟随数据变化"><a href="#8、如何让柱状图跟随数据变化" class="headerlink" title="8、如何让柱状图跟随数据变化"></a>8、如何让柱状图跟随数据变化</h2><p>答：1、创建SampledPositionProperty对象</p><p>2、在不同的时间点绑定对应的值</p><p>  将填充好的SampledPositionProperty赋值给dimensions，实现位置随时间的偏移</p><h2 id="9、如何加载天气图的效果"><a href="#9、如何加载天气图的效果" class="headerlink" title="9、如何加载天气图的效果"></a>9、如何加载天气图的效果</h2><p>答：1、使用Wind3D类实现</p><p>实现原理是将nc格式的数据解析之后运用primitive绘制</p><p>​    2、Cesium官网有github的分享案例，需要修改鼠标事件影响该类绘制时的显示隐藏</p><h2 id="10、如何给cesium地球替换表面图层"><a href="#10、如何给cesium地球替换表面图层" class="headerlink" title="10、如何给cesium地球替换表面图层"></a>10、如何给cesium地球替换表面图层</h2><p>答：1、主要是在viewer的imageryLayers地图层级内对单独的layer图层的显示隐藏或者添加与移除，imageryLayers有add与remove方法</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2、viewer.imageryLayers.addImageryProvider(layer, num);</span><br><span class="line">viewer.imageryLayers.remove(viewer.imageryLayers.get(num), true);</span><br></pre></td></tr></table></figure><p>主要是这两个API<br>    3、注意不同的地图图层加载会有对应的投影方式，比如web墨卡托投影和wgs84</p><h2 id="11、cesium如何进行坐标转换"><a href="#11、cesium如何进行坐标转换" class="headerlink" title="11、cesium如何进行坐标转换"></a>11、cesium如何进行坐标转换</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">答：1、//经纬度转屏幕坐标</span><br><span class="line"></span><br><span class="line">LngLatToSceenCoordinates(lng, lat) &#123;</span><br><span class="line"></span><br><span class="line">let cartesian3 = Cesium.Cartesian3.fromDegrees(lng, lat);</span><br><span class="line"></span><br><span class="line">let cartesian2 = Cesium.SceneTransforms.wgs84ToWindowCoordinates(</span><br><span class="line"></span><br><span class="line">viewer.scene,</span><br><span class="line"></span><br><span class="line">cartesian3</span><br><span class="line"></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">return cartesian2;</span><br><span class="line"></span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line">2、 //笛卡尔坐标转经纬度坐标</span><br><span class="line"></span><br><span class="line">Cartesian3ToLngLat(cartesian) &#123;</span><br><span class="line"></span><br><span class="line">let cartographic =</span><br><span class="line"></span><br><span class="line">viewer.scene.globe.ellipsoid.cartesianToCartographic(cartesian);</span><br><span class="line"></span><br><span class="line">let c_height = viewer.camera.positionCartographic.height;</span><br><span class="line"></span><br><span class="line">//将地图坐标（弧度）转为十进制的度数</span><br><span class="line"></span><br><span class="line">let lat_String = Cesium.Math.toDegrees(cartographic.latitude).toFixed(6);</span><br><span class="line"></span><br><span class="line">let log_String = Cesium.Math.toDegrees(cartographic.longitude).toFixed(6);</span><br><span class="line"></span><br><span class="line">return [</span><br><span class="line"></span><br><span class="line">parseFloat(log_String),</span><br><span class="line"></span><br><span class="line">parseFloat(lat_String),</span><br><span class="line"></span><br><span class="line">parseFloat(c_height),</span><br><span class="line"></span><br><span class="line">];</span><br><span class="line"></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><h2 id="12、cesium如何实现标记的添加"><a href="#12、cesium如何实现标记的添加" class="headerlink" title="12、cesium如何实现标记的添加"></a>12、cesium如何实现标记的添加</h2><p>  答：1、创建entity实体对象使用billboard对象场景图标挥着使用billboard collection使用primitive创建</p><h2 id="13、cesium如何实现鼠标拾取弹窗功能"><a href="#13、cesium如何实现鼠标拾取弹窗功能" class="headerlink" title="13、cesium如何实现鼠标拾取弹窗功能"></a>13、cesium如何实现鼠标拾取弹窗功能</h2><p>   答：1、创建new Cesium.ScreenSpaceEventHandler(canvas)对象</p><p> 2、注册鼠标点击事件<br>   3、使用let pick &#x3D; viewer.scene.pick(movement.position); 选取当前的entity</p><h2 id="14、如何设置cesium中的抗锯齿方法"><a href="#14、如何设置cesium中的抗锯齿方法" class="headerlink" title="14、如何设置cesium中的抗锯齿方法"></a>14、如何设置cesium中的抗锯齿方法</h2><p>  答：1、使用fxaa方法，效果较差</p><p>  2、使用msaa方法，但需要浏览器支持webGL2的api方法</p><p><img src="https://bcn.135editor.com/files/images/editor_styles/2b4dad3b5ce0324eb63cde4380e4cdfb.gif" alt="img"></p><p><img src="https://image2.135editor.com/cache/remote/aHR0cHM6Ly9tbWJpei5xbG9nby5jbi9tbWJpel9wbmcvdm5UNGhiYUxvWDZIWkQxZXFvRmljVXdwR3RPSklNamNzaWNNVVVZWDRvNHNNMGhQQ2RQRUtTV0pIYkdQb2MyVWJQaWNGVlNTM2ljU3hZRDdoOTdNUHYwSW9BLzA/d3hfZm10PXBuZw==" alt="img"></p><p><img src="https://bcn.135editor.com/files/images/editor_styles/8a370d08cb8dee16148088fd86f39e16.png" alt="img"></p><p><img src="https://bexp.135editor.com/files/users/498/4980660/202302/k5PHuh8T_I5qb.jpg?auth_key=1677427199-0-0-d90c72020ea7995dbf533d91bb976f8c" alt="qrcode_for_gh_e879ec750214_258.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cesium </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多边形</title>
      <link href="/posts/undefined/"/>
      <url>/posts/undefined/</url>
      
        <content type="html"><![CDATA[<h3 id="Voronoi-多边形"><a href="#Voronoi-多边形" class="headerlink" title="Voronoi 多边形"></a>Voronoi 多边形</h3><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/blogs/image-20230708212920053.png" alt="image-20230708212920053"></p><p>Voronoi 多边形，也称为 Voronoi 图或 Voronoi 分割，是一种空间分析和几何计算方法，用于将平面或空间划分为不同区域，每个区域都与给定一组点最近邻。这些区域被称为 Voronoi 多边形或 Voronoi 区域，每个多边形由与其对应的点作为最近邻点。</p><p>Voronoi 多边形的生成过程基于以下原则：给定一组点，每个点的 Voronoi 区域包含所有离该点最近的点，并且这些点之间的边界形成多边形。Voronoi 多边形的边界由平分相邻点之间的直线或曲线段组成，这些直线或曲线段是两个点之间的等距离线，也称为 Voronoi 边。因此，Voronoi 多边形的边界是相邻点之间的中垂线。</p><p>Voronoi 多边形在各种领域中有广泛应用，包括计算机图形学、计算机视觉、地理信息系统（GIS）、模式识别等。以下是一些应用 Voronoi 多边形的示例：</p><ol><li><p>空间分析：Voronoi 多边形可用于将地理空间划分为不同的区域，每个区域都由最近邻点决定。这在地理学、城市规划和环境分析中具有重要作用，可以用于确定服务设施的服务范围、确定地理区域的边界等。</p></li><li><p>面积计算：通过计算 Voronoi 多边形的面积，可以了解每个点的影响范围或区域的大小。这在生态学、资源管理和人口统计学中很有用。</p></li><li><p>最近邻搜索：Voronoi 多边形可用于确定给定点的最近邻点。这在图像处理、模式识别和计算机视觉中经常使用，例如图像中的特征匹配、对象识别等。</p></li><li><p>网格生成：Voronoi 多边形可以用作生成网格的方法之一。通过将点集表示为 Voronoi 图，可以生成规则且适应性良好的网格，这在数值计算和有限元分析中很有用。</p></li></ol><p>总之，Voronoi 多边形是一种强大的几何计算工具，可用于空间分析、最近邻搜索、面积计算和网格生成等应用领域。它提供了一种有效的方法来划分空间并了解点之间的关系，为许多问题的解决提供了有力支持。</p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>convex</title>
      <link href="/posts/e911cef5/"/>
      <url>/posts/e911cef5/</url>
      
        <content type="html"><![CDATA[<p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/blogs/image-20230708212656757.png" alt="image-20230708212656757"></p><h3 id="平面地图综合中的convex-hull-差分组合"><a href="#平面地图综合中的convex-hull-差分组合" class="headerlink" title="平面地图综合中的convex hull+差分组合"></a>平面地图综合中的convex hull+差分组合</h3><p>平面地图综合中的 “convex hull + 差分组合” 是一种常用的地理信息处理方法，用于合并多个重叠的平面地图数据集，以生成一个较大范围的一致地图。</p><p>首先，让我们解释一下 “convex hull” 和 “差分组合” 的含义：</p><ol><li><p>Convex Hull（凸包）：凸包是一个几何概念，用于描述一个点集的最小凸多边形。对于给定的点集，凸包是包围这些点的最小凸形状，即没有凹陷的形状。在地图综合中，凸包可以用于找到每个地图数据集的边界。</p></li><li><p>差分组合：差分组合是指将两个或多个数据集进行差分操作，以便将它们合并成一个单一的数据集。在地图综合中，差分组合用于合并多个地图数据集，消除重叠和冗余部分。</p></li></ol><p>现在我们来详细介绍 “convex hull + 差分组合” 的过程：</p><ol><li><p>Convex Hull（凸包）：对于每个地图数据集，首先计算该数据集中所有点的凸包。这可以使用凸包算法，例如Graham扫描算法或Jarvis步进算法。凸包的边界定义了该数据集的外围形状。</p></li><li><p>差分操作：通过对每个地图数据集的凸包进行差分操作，可以消除重叠和冗余的部分。差分操作可以通过将边界相交的部分进行裁剪来实现，从而确保每个数据集的边界只包含在该数据集内的部分。</p></li><li><p>组合数据集：将经过差分操作后的每个数据集的边界进行组合，以生成一个新的、一致的地图数据集。这可以通过将每个数据集的边界多边形进行合并或拼接来实现。最终的合并结果将是一个不重叠且连续的边界，代表了整个地图范围。</p></li></ol><p>这种 “convex hull + 差分组合” 的方法在平面地图综合中很有用，因为它能够合并多个重叠的地图数据集，同时消除重叠和冗余的部分。通过计算凸包和执行差分操作，可以获得一个一致且完整的地图，而不会丢失任何细节或引入不一致的边界。</p><p>需要注意的是，实际的实现可能会涉及更复杂的步骤和算法，具体取决于地图数据的类型和处理需求。此外，该方法还可能需要处理边界相交的情况，以确保生成的地图数据集</p><p>是连续且完整的。因此，在实际应用中，可能需要考虑处理重叠、边界修复和边界连接等问题，以获得高质量的地图综合结果。</p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>八叉树结构</title>
      <link href="/posts/f4dabd3f/"/>
      <url>/posts/f4dabd3f/</url>
      
        <content type="html"><![CDATA[<h3 id="八叉树结构"><a href="#八叉树结构" class="headerlink" title="八叉树结构"></a>八叉树结构</h3><p>八叉树（Octree）是一种常用的树型数据结构，它是二叉树在三维空间中的扩展。八叉树被广泛应用于计算机图形学、空间分区和体积渲染等领域，用于高效地表示和处理三维空间的数据。</p><p>八叉树的基本思想是将三维空间递归地划分为八个等大小的子空间，每个子空间称为一个八叉树节点（Octant）。这种划分方式类似于将立方体分成八个等大小的小立方体。每个节点可以有三种可能的状态：</p><ol><li>叶节点（Leaf Node）：表示当前空间内存在数据或对象，不再继续划分。</li><li>空节点（Empty Node）：表示当前空间内不存在数据或对象，不再继续划分。</li><li>分支节点（Branch Node）：表示当前空间内可能存在数据或对象，需要进一步划分。</li></ol><p>八叉树的构建过程从一个包含所有数据的根节点开始，根据数据的分布情况，逐层划分空间直到满足停止条件。停止条件可以是树的深度达到预定的最大深度，或者节点内的数据数量达到某个阈值。</p><p>八叉树的用法主要有以下几个方面：</p><ol><li><p>空间分区：八叉树可以将三维空间划分为多个小空间，用于高效地管理和查询空间中的数据。在计算机图形学中，八叉树常被用来表示场景中的物体，以便进行快速的碰撞检测和可视化剔除。</p></li><li><p>数据压缩：八叉树可以用来压缩表示稀疏的三维数据。对于只在部分空间中存在数据的情况，八叉树可以有效地存储和表示这些数据，减少存储空间和访问成本。</p></li><li><p>体积渲染：在体积渲染（Volume Rendering）中，八叉树被广泛应用于表示和处理体数据。通过将体数据划分为八叉树节点，可以高效地实现体积数据的可视化和交互式浏览。</p></li><li><p>点云处理：对于三维点云数据，八叉树可以用于加速点云的搜索和查询操作。通过将点云数据划分为八叉树节点，可以快速地找到与给定查询点最近的点或区域。</p></li></ol><p>总的来说，八叉树是一种灵活且高效的数据结构，适用于处理和</p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前馈神经网路</title>
      <link href="/posts/169d769d/"/>
      <url>/posts/169d769d/</url>
      
        <content type="html"><![CDATA[<h1 id="前馈神经网路"><a href="#前馈神经网路" class="headerlink" title="前馈神经网路"></a>前馈神经网路</h1><h2 id="1、简单介绍"><a href="#1、简单介绍" class="headerlink" title="1、简单介绍"></a>1、简单介绍</h2><p><strong>前馈神经网络（Feedforward Neural Network，简称FNN）</strong>是一种基本的神经网络模型，它最早由美国心理学家Rosenblatt在1958年提出，是最早的一种神经网络模型。FNN的每个神经元都是单向连接的，信号只能从输入层流向输出层，不存在反馈（recurrent）的过程，因此也被称为“无记忆神经网络”。</p><p>FNN由输入层、隐藏层和输出层构成，其中输入层接收外部输入，输出层输出结果，而隐藏层则负责处理输入层的信息，提取出特征并将其传递给输出层。隐藏层通常包含多个神经元，每个神经元都连接着上一层的所有神经元和下一层的所有神经元。FNN的输出是根据输入与每个神经元之间的连接权值进行计算得出的。</p><p>FNN的训练过程通常是基于反向传播算法（Back Propagation，简称BP算法），该算法利用梯度下降法对网络参数进行调整，使得网络的输出结果能够逐渐逼近期望的输出结果。BP算法的基本思想是将误差逐层反向传播，并根据误差值对网络参数进行调整，以达到误差最小化的目的。在实际应用中，常常需要对神经网络进行大量的训练，以提高网络的泛化能力。</p><p>FNN在模式识别、数据挖掘、自然语言处理等领域中有广泛的应用，它能够有效地处理多维度、非线性和复杂的数据，具有良好的分类和预测性能。同时，FNN也具有一定的适应性，能够适应不同的数据类型和数据规模，并且具有良好的可扩展性，可以通过增加神经元和层数来提高网络的性能。</p><h2 id="2、"><a href="#2、" class="headerlink" title="2、"></a>2、</h2><p>目标：近似一些未知的理想函数</p><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325160313002.png" alt="image-20230325160313002"></p><p>理想分类器：<img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325160616559.png" alt="image-20230325160616559"></p><p>前馈网络：定义映射：<img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325160644995.png" alt="image-20230325160644995"></p><p>从可用的样本中学习参数<img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325160727626.png" alt="image-20230325160727626"></p><p>获得f*地较好的近似</p><p>信息流从输入开始贵，经过中间计算（即函数映射），生成类别</p><p>没有反馈连接（循环网络）</p><h2 id="3、"><a href="#3、" class="headerlink" title="3、"></a>3、</h2><p>函数f是许多不同函数的组合，例如：<img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325161151241.png" alt="image-20230325161151241"></p><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325161207536.png" alt="image-20230325161207536"></p><ul><li><p><input checked="" disabled="" type="checkbox"> 函数结构可以用有向无环图来描述（因此称为前馈网络）；</p></li><li><p><input checked="" disabled="" type="checkbox"> f（1）是第一层f（2）是第二层，以此类推；</p></li><li><p><input checked="" disabled="" type="checkbox"> 深度是函数组合链中最大的i</p></li><li><p><input checked="" disabled="" type="checkbox"> 最后一层称为输出层</p></li></ul><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325202045174.png" alt="image-20230325202045174"></p><h2 id="4、线性模型"><a href="#4、线性模型" class="headerlink" title="4、线性模型"></a>4、线性模型</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230325202418699.png" alt="image-20230325202418699"></p><h2 id="5、设计决策"><a href="#5、设计决策" class="headerlink" title="5、设计决策"></a>5、设计决策</h2><p>1、需要选择优化器、损失函数和输出形式</p><p>2、选择激活函数</p><p>3、机构设计（网络层数等）</p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>反向传播算法</title>
      <link href="/posts/437097cd/"/>
      <url>/posts/437097cd/</url>
      
        <content type="html"><![CDATA[<h1 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h1><h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>反向传播算法是一种用于训练人工神经网络的优化算法。它利用梯度下降法来最小化神经网络的损失函数，并更新网络参数以提高模型的准确性。下面是反向传播算法的详细介绍。</p><p>反向传播算法的基本原理是利用链式法则（chain rule）来计算损失函数相对于每个网络参数的梯度。该算法从输出层开始，计算每个参数的梯度，并向后逐层传播，直到达到输入层。在每一层中，算法通过将该层的梯度与下一层的梯度相乘来计算该层的梯度。这个过程反向传播了误差，因此称为反向传播算法。</p><p>反向传播算法的步骤如下：</p><p>前向传播：对于给定的输入样本，计算神经网络的输出结果。</p><p>计算误差：将神经网络的输出结果与真实结果进行比较，并计算误差。误差通常使用损失函数（例如均方误差）来表示。</p><p>反向传播误差：从输出层开始，计算每个参数的梯度，并向后逐层传播，直到达到输入层。</p><p>更新参数：使用梯度下降法来更新神经网络的参数，以最小化损失函数。梯度下降法的目标是沿着梯度的相反方向更新参数，以使损失函数最小化。</p><p>重复步骤1-4，直到达到停止条件，例如达到最大迭代次数或达到期望的训练误差。</p><p>反向传播算法的优点是它可以处理复杂的非线性模型，并且可以使用梯度下降法快速优化模型参数。然而，该算法也存在一些缺点，例如容易陷入局部最优解，对初始权重值和学习率等参数敏感，以及可能存在梯度消失或爆炸的问题。</p><p>为了克服这些问题，研究人员已经提出了许多改进的反向传播算法，例如随机梯度下降法（SGD）、动量优化法（Momentum）、自适应学习率优化法（Adagrad、Adadelta、Adam等）等。这些算法使得神经网络的训练更加稳定和高效。</p><h2 id="2、如何学习权值"><a href="#2、如何学习权值" class="headerlink" title="2、如何学习权值"></a>2、如何学习权值</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326142148946.png" alt="image-20230326142148946"></p><p>1、初步想法：随机扰动一个权重，看看它是否提高了性能，而后保存更改</p><p>2、非常低效：对于一个权重的改变，需要在样本集上进行多次传递</p><p>3、其他想法：同时扰动所有权重，并将性能的提高与权重的变化联系起来</p><p>4、非常难以实现</p><p>5、所以：只扰动激活值（因为他门数量较少）但同样低效</p><h2 id="3、反向传播"><a href="#3、反向传播" class="headerlink" title="3、反向传播"></a>3、反向传播</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326142734973.png" alt="image-20230326142734973"></p><p>1、前向传播：接受输入x，通过中间阶段，获得输出y</p><p>2、训练结算：利用y计算标量损失</p><p>3、反向传播允许信息从损失函数反向流动来计算梯度</p><p>4、从训练数据来看，我们不知道隐藏的单元效果</p><p>5、但是，当我们改版一个隐藏的激活时，我们可以得到误差传播的速度</p><p>6、使用误差导数，也称之为hidden activites</p><p>7、每个隐藏的单元可以影响许多输出单元</p><p>8、单独的误差影响-&gt;合并这些影响</p><p>9、可以有效地计算隐藏单元的误差导数（一旦我们有了隐藏激活的误差导致，就很容易得到权重的误差导数）</p><h2 id="4、示例"><a href="#4、示例" class="headerlink" title="4、示例"></a>4、示例</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326143902055.png" alt="image-20230326143902055"></p><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326144435509.png" alt="image-20230326144435509"></p><h2 id="5、多维输出"><a href="#5、多维输出" class="headerlink" title="5、多维输出"></a>5、多维输出</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326145051267.png" alt="image-20230326145051267"></p><h2 id="6、实践"><a href="#6、实践" class="headerlink" title="6、实践"></a>6、实践</h2><ol><li>由上面的推导过程可以看到，反向传播就i是不断地利用求导的链式法则进行展开的过程；</li><li>这样的过程并不复杂，但是实际网络规模个很大的情况下非常繁琐，需要细心操作</li><li>常用的深度学习框架（Pytorch、Tensorflow）中均不需要我们手动编码进行反向传播</li><li>只要我们将前向传播的Tensor流动路径定义清楚，框架会自动帮助我们计算梯度并反传更新权值；</li><li>我们只需要关心损失函数的定义，网络框架的搭建等等更加宏观的内容</li><li>需要保证Tensor流图中的每一个Tensor均可以进行反向传播（例如Pytorch中需要关注requires——grade是否为true）</li></ol><h2 id="7、随机梯度下降"><a href="#7、随机梯度下降" class="headerlink" title="7、随机梯度下降"></a>7、随机梯度下降</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326150031055.png" alt="image-20230326150031055"></p><h2 id="8、Mini-batch随机梯度下降"><a href="#8、Mini-batch随机梯度下降" class="headerlink" title="8、Mini-batch随机梯度下降"></a>8、Mini-batch随机梯度下降</h2><p><img src="http://rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230326150113608.png" alt="image-20230326150113608"></p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Delaunay三角网</title>
      <link href="/posts/65ce02f4/"/>
      <url>/posts/65ce02f4/</url>
      
        <content type="html"><![CDATA[<h3 id="Delaunay-三角网"><a href="#Delaunay-三角网" class="headerlink" title="Delaunay 三角网"></a>Delaunay 三角网</h3><p>Delaunay 三角网是计算几何学中的一种三角剖分方法，用于将给定的点集合连接成不重叠且无内部点的三角形组成的网格结构。Delaunay 三角网具有一些重要的性质，使其在许多应用领域中得到广泛应用，例如计算机图形学、计算机视觉、地理信息系统和有限元分析等。</p><p>Delaunay 三角网的生成过程基于以下原则：给定一组点，如果点集中没有任何点在某个三角形的外接圆内部，则该三角形属于 Delaunay 三角网。换句话说，Delaunay 三角网中的任何一个三角形都满足其外接圆不包含其他点。这个性质使得 Delaunay 三角网具有最大化最小角的特点，使得三角形的形状更加均匀和稳定。</p><p>Delaunay 三角网的生成可以使用多种算法，其中最常用的是Bowyer-Watson算法，其基本思想如下：</p><ol><li><p>初始化：将点集中的几个点组成一个超级三角形，该超级三角形完全包含所有的点。</p></li><li><p>逐点插入：对于点集中的每个点，将其插入到当前的 Delaunay 三角网中。</p></li><li><p>修复：对于每个新插入的点，需要更新 Delaunay 三角网，确保满足 Delaunay 性质。这涉及到删除包含新点的三角形，然后重新连接形成新的三角形。</p></li><li><p>结束：当所有点都被插入并且网格满足 Delaunay 性质时，生成的三角网即为 Delaunay 三角网。</p></li></ol><p>Delaunay 三角网具有许多重要的性质，使其在实际应用中得到广泛应用：</p><ol><li><p>最大化最小角：Delaunay 三角网的三角形具有最大化最小角的特点，使得网格中的三角形形状更加均匀和稳定，有利于数值计算和模拟分析。</p></li><li><p>最小化边长：Delaunay 三角网的边长相对较小，可以提高网格的精度和拟合性能。</p></li><li><p>惟一性：给定一组点，对应的 Delaunay 三角网是唯一的，无论使用何种算法生成。</p></li><li><p>局部特性：Delaunay 三角网的局部结构与周围的点有关，当添加、删除或移动一个点时，只需要更新相邻的三角形，而不需要对整个网格进行重新计算。</p></li></ol><p>Delaunay 三</p><p>角网在许多领域中有广泛的应用，包括但不限于以下几个方面：</p><ol><li><p>计算机图形学：Delaunay 三角网可以用于生成高质量的三角网格，用于三维建模、形状重建、表面重建和体积渲染等任务。它能够确保生成的三角形形状合理，且没有不良的尖角或扭曲。</p></li><li><p>计算机视觉：Delaunay 三角网在图像处理和计算机视觉中扮演重要角色。例如，在图像拼接和图像配准中，可以使用 Delaunay 三角网进行特征点匹配和对齐。</p></li><li><p>地理信息系统（GIS）：Delaunay 三角网可用于对地理数据进行空间分析和处理。它可以用于地形建模、地貌分析、地理插值和地图绘制等任务。</p></li><li><p>有限元分析：Delaunay 三角网可作为有限元方法中的基础网格。它能够提供高质量的网格，用于模拟和分析复杂结构的物理行为，如弹性力学、流体力学和电磁场分析。</p></li><li><p>最近邻搜索：Delaunay 三角网的拓扑结构可以用于高效地搜索点集中某个点的最近邻。这在模式识别、数据挖掘和机器学习中是一个常见的任务。</p></li><li><p>仿真与优化：Delaunay 三角网可以作为仿真和优化算法的输入数据结构。它可以用于优化路径规划、传感器布局、机器人导航等应用，以提高系统的效率和性能。</p></li></ol><p>总结而言，Delaunay 三角网是一种强大的几何计算工具，具有均匀性、稳定性和最优化性质。它在计算机图形学、计算机视觉、地理信息系统、有限元分析等领域发挥着重要作用，并提供了许多实际问题的解决方案。</p><p><img src="/rx6zk4j2b.hn-bkt.clouddn.com/%E5%8D%9A%E5%AE%A2/image-20230706110328246.png" alt="image-20230706110328246"></p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>序言</title>
      <link href="/posts/4a17b156/"/>
      <url>/posts/4a17b156/</url>
      
        <content type="html"><![CDATA[<p>序言</p><p>欢迎来到我的博客！在这个快速发展的数字时代，技术成为推动社会进步和创新的关键力量。作为一个对技术充满热情的人，我创建了这个博客网站，旨在与大家分享我的知识和经验，特别是在前端、后端和GIS等技术领域。</p><p>我相信技术的力量可以改变世界，而这个博客是我为了将这种信念传递给更多人而建立的。在这里，我将探索各种前沿技术、最佳实践和创新思维，希望能够激发你的灵感，并帮助你在技术的海洋中航行。</p><p>在前端方面，我将分享关于HTML、CSS和JavaScript等技术的最新趋势和最佳实践。你将了解到如何构建漂亮、响应式和交互式的用户界面，以及如何优化网站的性能和用户体验。</p><p>对于后端开发，我将深入探讨各种编程语言和框架，如Python、Java和Node.js等，以及数据库设计和API开发。你将学习到如何构建强大的后端系统，实现数据存储、处理和传输，以及如何设计可扩展和高性能的应用程序。</p><p>另外，我对地理信息系统（GIS）也有浓厚的兴趣。GIS技术结合了地理数据和信息系统，可以用于地图制作、空间分析和位置智能等领域。我将分享GIS的基础知识、工具和应用案例，帮助你了解如何利用地理空间数据解决现实世界的问题。</p><p>通过这个博客网站，我希望能够建立一个技术交流和学习的社区。我鼓励读者们积极参与讨论，提出问题和分享自己的见解。只有通过不断的学习和合作，我们才能够共同成长，并推动技术的进步。</p><p>最后，感谢你的光临！我希望我的博客能为你提供有价值的内容，激发你的创造力和求知欲。如果你对任何技术相关的话题感兴趣，或者有任何问题和建议，都请留言给我。让我们一起踏上这个技术之旅，共同探索无限可能！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>绪论与深度学习概述</title>
      <link href="/posts/63e551d2/"/>
      <url>/posts/63e551d2/</url>
      
        <content type="html"><![CDATA[<h1 id="绪论与深度学习概述"><a href="#绪论与深度学习概述" class="headerlink" title="绪论与深度学习概述"></a>绪论与深度学习概述</h1><h2 id="1-起源与发展"><a href="#1-起源与发展" class="headerlink" title="1.起源与发展"></a>1.起源与发展</h2><p>第一阶段(1943 -1969)</p><p>1943年：Warren McCulloch和Walter Pitts提出了MP神经元模型<br>1958年：Frank Rosenblatt提出了感知器(Perceptron)<br>1960年：Bernard Widrow和Ted Hoff提出了ADLINE神经网络<br>1969年：Marvin Minsky和Seymour Papert指出感知器只能做简单的线性分类任务，无法解决XOR这种简单分类问题<br>第二阶段(1980 -1989)</p><p>1982年：John Hopfield提出了Hopfield神经网络<br>1986年：David Rumelhart、Geoffrey Hinton和Ronald Williams提 出了误差反向传播算法(Error Back Propagation, BP)<br>1989年:YannLeCun等人提出了卷积神经网络(Convolutional Neural Networks，CNN)<br>第三阶段(2006 - )</p><p>2006年:Hinton和他的学生正式提出了深度学习的概念，通过无监督学习方法逐层训练算法，再使用有监督的反向传播算法进行调优</p><p>2011年:Frank Seide在语音识别基准测试数据集上获得压倒性优势</p><p>2012年:AlexKrizhevsky在CNN中引入ReLU激活函数，在图像识别基准测试中获得压倒性优势。</p><p>2012年：吴恩达(Andrew Ng)教授和谷歌首席架构师Jeff Dean共 同主导著名的GoogleBrain项目，采用16万个CPU来构建一个深层 神经网络——DNN，将其应用于图像和语音的识别，大获成功</p><p>2014年：Facebook的DeepFace项目，在人脸识别方面的准确率已 经能够达到97%以上，跟人类识别的准确率几乎没有差别</p><p>2016年：谷歌DeepMind开发的AlphaGo以4:1的比分战胜国际顶尖 围棋高手李世石，证明在围棋领域，基于深度学习技术的机器人已</p><p>经超越了人类</p><h2 id="2-重要的研究机构和著名科学家"><a href="#2-重要的研究机构和著名科学家" class="headerlink" title="2.重要的研究机构和著名科学家"></a>2.重要的研究机构和著名科学家</h2><p>深度学习研究机构<br>Machine Learning at University of Toronto<br>代表人物：GeoffreyHinton</p><p>1.4<br>Deepmind at Google<br>1.5<br>AI research at Facebook<br>清华大学AI研究院<br>中国科学院自动化所<br>中国科学院数学与系统科学研究院<br>Tencent AI Lab<br>华为诺亚方舟实验室<br>阿里达摩院<br>…<br>深度学习知名科学家<br>Geoffrey Hinton<br>深度学习之父；多伦多大学杰出教授；Google副总裁及首席科学顾问；英国皇家科学院院士，美国国家工 程院外籍院士，美国艺术与科学院 外籍院士。</p><p>在BP算法，Boltzmannmachines, Time-delay neural nets, Variational learning and Deep learning做出杰出文献。</p><p>Yann LeCun<br>卷积神经网络之父；纽约大学杰出教授；Facebook人工智能实验室负责人；纽约大学数据科学实验室创始人。</p><p>在学习理论与学习算法、卷积神经 网络领域做出杰出文献。</p><p>Yoshua Bengio<br>蒙特利尔大学全职教授；加拿大统计学习算法研究主席；加拿大皇家科学院院士；CIFAR Senior Fellow；创办了ICLR国际会议。</p><p>在MachineLearning，Deeplearning 领域做出杰出文献。</p><p>吴恩达(Andrew Ng)<br>斯坦福大学计算机科学系和电子工程系副教授；在线教育平台Coursera的联合创始人(with Daphne Koller)；2014年5月16日，吴恩达加入百度，担任百度公司首席科学家；2017年10月，吴恩达出任Woebot公司新任董事长。</p><h2 id="3-深度学习的定义和主要应用"><a href="#3-深度学习的定义和主要应用" class="headerlink" title="3.深度学习的定义和主要应用"></a>3.深度学习的定义和主要应用</h2><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p>深度学习定义：一般是指通过训练多层网络结构对未知数据进行分类或者回归</p><p>深度学习分类：有监督学习方法&#x3D;&#x3D;深度前馈网络、卷积神经网络、循环神经网络等；无监督先学习方法&#x3D;&#x3D;深度信念网、深度玻尔兹曼机，深度自编码器等。</p><h5 id="主要应用"><a href="#主要应用" class="headerlink" title="主要应用"></a>主要应用</h5><p>图像处理领域主要应用</p><p>​1.图像分类（物体识别）：整幅图像的分类或识别</p><p>​2.物体检测：检测图像中物体的位置进而识别物体</p><p>​3.图像分割：对图像中特定物体按边缘进行分割</p><p>​4.图像回归：预测图像中物体组成部分的坐标</p><p>语音识别领域主要应用</p><p>​1.语音识别：将语音识别为文字</p><p>​2.声纹识别：识别那个人的声音</p><p>​3.语音合成：根据文字合成特定人的语音</p><p>自然语言处理领域主要应用</p><p>​1.语言模型：根据之前词预测下一个单词。</p><p>​2.情感分析：分析文本体现的情感（正负向、正负中或多态度类型）</p><p>​3.神经机器翻译：基于统计语言模型的多语种互译</p><p>​4.神经自动摘要：根据文本自动生成摘要</p><p>​5.机器阅读理解：通过阅读文本回答问题，完成选择题或者完形填空。</p><p>​6.自然语言推理：根据一句话（前提）推出另一句话（结论）</p><p>综合应用</p><p>​1.图像描述：根据图像给出图像的描述句子</p><p>​2.可视问答：根据图像或视频回答问题</p><p>​3.图像生成：根据文本描述生成图像</p><p>​4.视频生成：根据事故自动生成视频</p><h1 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h1><p>数学基础：</p><p>​1.张量、矩阵运算、矩阵的基础知识、矩阵分解</p><p>​2.概况统计、常见的（多变量）分布</p><p>​3.信息论、熵、互信息、相对熵、交叉熵</p><p>​4.最优化估计方法、最小二乘、线性模型</p><h2 id="矩阵论"><a href="#矩阵论" class="headerlink" title="矩阵论"></a>矩阵论</h2><h5 id="矩阵基本知识"><a href="#矩阵基本知识" class="headerlink" title="矩阵基本知识"></a>矩阵基本知识</h5><p>矩阵：是一个二维数组，其中的每一个元素一般由两个索引来确定一般用大写变量表示，m行n列的实数矩阵基座A∈R m×n</p><p>张量（Tensor）：是矢量概念推广，可以用来表示在一些矢量，标量和其他张量之间的线性关系的多线性函数，标量是0阶张量，矢量是一阶张量，矩阵是二阶张量，三维及以上数组一般称张量</p><p>矩阵的秩（Rank）：矩阵列向量中的极大线性无关组的数目，记作列秩，同样可以定义行秩，行秩&#x3D;列秩&#x3D;矩阵的秩，通常记作rank（A）</p><h6 id="矩阵的逆"><a href="#矩阵的逆" class="headerlink" title="矩阵的逆"></a>矩阵的逆</h6><p>​1.若矩阵A为方阵，当rank（An*n）&lt;n 时，称A为奇异矩阵或不可逆矩阵</p><p>​1.若矩阵A为方阵，当rank（An*n）&#x3D;n 时，称A为非奇异矩阵或可逆矩阵</p><p>其逆矩阵 A−1 满足以下条件，则称 A−1 为矩阵A的逆矩阵：AA−1&#x3D;A−1A&#x3D;In其中 In是 n×n 的单位阵。</p><h6 id="矩阵的广义逆矩阵"><a href="#矩阵的广义逆矩阵" class="headerlink" title="矩阵的广义逆矩阵"></a>矩阵的广义逆矩阵</h6><p>​1.如果矩阵部位方阵或者时奇异矩阵，不存在逆矩阵，但是可以计算其广义矩阵或者伪逆矩阵；</p><p>​2.对于矩阵A，如果存在矩阵B使得ABA &#x3D; A 则称B为A的广义逆矩阵</p><h6 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h6><p>​机器学习中常见的矩阵分解有特征分解和奇异值分解</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115162935710.png" alt="image-20211115162935710"></p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115163018963.png" alt="image-20211115163018963"></p><h2 id="概率统计"><a href="#概率统计" class="headerlink" title="概率统计"></a>概率统计</h2><h5 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h5><h5 id="常见的概率分布"><a href="#常见的概率分布" class="headerlink" title="常见的概率分布"></a>常见的概率分布</h5><h6 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a>伯努利分布</h6><p>​1.伯努利试验：只可能有两种结果的单次随机实验</p><p>​2.又称0-1分布，单个二值型离散随机变量分布</p><p>​3.其概率分布：P * （* X &#x3D; 1） &#x3D; p，P（X &#x3D; 0） &#x3D; 1-p</p><h6 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h6><h6 id="均匀分布"><a href="#均匀分布" class="headerlink" title="均匀分布"></a>均匀分布</h6><h6 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h6><h6 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h6><h2 id="多变量概率分布"><a href="#多变量概率分布" class="headerlink" title="多变量概率分布"></a>多变量概率分布</h2><h5 id="条件概率、联合概率、先验概率、后验概率、全概率公式、贝叶斯公式"><a href="#条件概率、联合概率、先验概率、后验概率、全概率公式、贝叶斯公式" class="headerlink" title="条件概率、联合概率、先验概率、后验概率、全概率公式、贝叶斯公式"></a>条件概率、联合概率、先验概率、后验概率、全概率公式、贝叶斯公式</h5><h4 id="常用统计量"><a href="#常用统计量" class="headerlink" title="常用统计量"></a>常用统计量</h4><p>方差、协方差</p><h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><h4 id="熵（Entropy）"><a href="#熵（Entropy）" class="headerlink" title="熵（Entropy）"></a>熵（Entropy）</h4><p>信息熵，可以看作时样本集合纯度一种指标，也可以认为是样本集合包含的平均信息量</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115164252558.png" alt="image-20211115164252558"></p><h4 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h4><p>两个随机变量X和Y的联合分布可以形成联合熵，度量二维随机变量XY的不确定性</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115164444579.png" alt="image-20211115164444579"></p><h4 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h4><p>在随机变量X发生的前提下，随机变量Y发生带来的熵，定义为Y的条件熵，用H（Y|X）表示，定义为：</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115164712189.png" alt="image-20211115164712189"></p><p>条件熵用来衡量在已知随机变量Y的不确定。熵、联合熵和条件熵之间的关系：H（Y|X）&#x3D; H(X,Y) - H(X)</p><h4 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h4><p>I(X;Y) &#x3D; H(X) + H(Y) - H(X,Y)</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115165257307.png" alt="image-20211115165257307"></p><h4 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h4><p>相对熵又称KL散度，是描述两个概率分布P和Q差异的一种方法，记作D(P||Q)。在信息论中，D(P||Q)表示用概率分布Q来拟合真实分布P时，产生的信息表达损耗，其中P表示信息源的真实分布，Q表示P的近似分布。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115165805151.png" alt="image-20211115165805151"></p><h4 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h4><p>一般用来求目标与预测值之间的差距，深度学习中经常用到的一类损失函数度量，比如在对抗生成网络（GAN）中</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115170103496.png" alt="image-20211115170103496"></p><p>交叉熵：<img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115170230305.png" alt="image-20211115170230305"></p><h2 id="最优化估计"><a href="#最优化估计" class="headerlink" title="最优化估计"></a>最优化估计</h2><h5 id="最小二乘估计"><a href="#最小二乘估计" class="headerlink" title="最小二乘估计"></a>最小二乘估计</h5><p>最小二乘估计又称最小平方法，是一种数学优化方法。它通过最小化误差的平方和寻找数据的最佳函数匹配。最小二乘法经常用于回归问题，可以方便的求得未知参数，比如曲线拟合，最小化能量或者最大化熵等问题。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211115170645981.png" alt="image-20211115170645981"></p><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>从人工智能、机器学习与深度学习的起源以及发展，包括各自的应用，都是后期的学习打下基础。以及数学基础，深度学习离不开数学，前期打下坚实的基础是非常重要的。</p><h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h1><h5 id="机器学习基础-1"><a href="#机器学习基础-1" class="headerlink" title="机器学习基础"></a>机器学习基础</h5><h5 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1.数据集"></a>1.数据集</h5><h5 id="2-误差分析"><a href="#2-误差分析" class="headerlink" title="2.误差分析"></a>2.误差分析</h5><h5 id="3-代表的机器学习方法"><a href="#3-代表的机器学习方法" class="headerlink" title="3.代表的机器学习方法"></a>3.代表的机器学习方法</h5><p>​1.有监督、线性回归、SVM、决策树、RF</p><p>​2.无监督、聚类、降维(PCA)</p><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><h5 id="基本概念：具体来说就是从已知数据中获取规律，并利用规律对未知数据进行预测的技术"><a href="#基本概念：具体来说就是从已知数据中获取规律，并利用规律对未知数据进行预测的技术" class="headerlink" title="基本概念：具体来说就是从已知数据中获取规律，并利用规律对未知数据进行预测的技术"></a>基本概念：具体来说就是从已知数据中获取规律，并利用规律对未知数据进行预测的技术</h5><h5 id="机器学习分类"><a href="#机器学习分类" class="headerlink" title="机器学习分类"></a>机器学习分类</h5><p>​1.有监督学习（SupervisedLearning)：有老师（环境）的情况下，学生（计算机）从老师（环境）哪里获得对错指示、最终答案的学习方法。<strong>跟学师评</strong></p><p>​2.无监督学习(UnsupervisedLearning)：没有老师(环境)的情况 下，学生(计算机)自学的过程，一般使用一些既定标准进行评价。 <strong>自学标评</strong></p><p>​3.强化学习(Reinforcement Learning)：没有老师(环境)的情况 下，学生(计算机)对问题答案进行自我评价的方法，<strong>自学自评</strong></p><h5 id="机器学习可做如下两种分类"><a href="#机器学习可做如下两种分类" class="headerlink" title="机器学习可做如下两种分类"></a>机器学习可做如下两种分类</h5><p>​1.有监督学习：代表任务“分类”和“回归”</p><p>​2.无监督分类：代表任务“聚类”和“降维”</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117144218571.png" alt="image-20211117144218571"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集：观测样本的集合。具体的<em>D</em>&#x3D;<em>x</em>1,<em>x</em>2,⋯,<em>xn</em> 表示一个包含<em>n</em>个样本的数据集，其中 <em>xi</em> 是一个向量，表示数据集的第𝑖个样本，其维度𝑑称为样本空间的维度。</p><p>向量<em>xi</em>的元素称为样本的特征，其取值可以是连续的，也可以是离散的。从数据集中学出模型的过程，便称为“学习”或“训练”</p><h3 id="数据集分类"><a href="#数据集分类" class="headerlink" title="数据集分类"></a>数据集分类</h3><p>​1.训练集(Trainingset)：用于模型拟合的数据样本</p><p>​2.验证集(Validation set)：是模型训练过程中单独留出来的样本集，它可以用于调整模型的超参数和用于对模型的能力进行初步评估；</p><p>​例如SVM中参数c（控制分类错误的惩罚程度）和核函数的选择，或者选择网络结构</p><p>​3.测试集(Testset)：用来评估最终模型的泛化能力，但不能作为调参，选择特征等算法相关的依据</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117145816797.png" alt="image-20211117145816797"></p><h3 id="常见数据集"><a href="#常见数据集" class="headerlink" title="常见数据集"></a>常见数据集</h3><p>图像分类</p><p>​1.MNIST(手写数字) <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></p><p>​2.CIFAR-10, CIFAR-100, ImageNet</p><p>​<a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></p><p>​<a href="http://www.image-net.org/">http://www.image-net.org/</a></p><p>电影评论情感分类</p><p>​1.Large Movie Review Dataset v1.0</p><p>​2.<a href="http://ai.stanford.edu/~amaas/data/sentiment/">http://ai.stanford.edu/~amaas/data/sentiment/</a></p><p>图像生成诗歌</p><p>​1.数据集:<a href="https://github.com/researchmm/img2poem">https://github.com/researchmm/img2poem</a></p><h2 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h2><p>误差是指算法实际预测输出与样本真实输出之间的差异</p><p>​1.模型在训练集上的误差称为“训练误差”</p><p>​2.模型在总体样本上的误差称为“泛化误差”</p><p>​3.模型在测试集上的误差称为“测试误差”</p><p>由于我们无法知道总体样本，多以我们只能尽量最小化训练误差，导致训练误差和泛化误差有可能存在明显的差异。</p><p>*<em>过拟合</em>  ：是指模型能很好的拟合训练样本，而无法很好地拟合测试样本的现象，从而导致泛型化性能下降，未防止”过拟合“可以选择减少参数，降低模型复杂度，正则化等</p><p>*<em>欠拟合</em>  ：是指模型还没有很好的训练出数据的一般规律。模型拟合程度不高的现象。为防止”欠拟合“，可以选择调整参数、增加迭代深度，换用更加复杂的模型</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117151858614.png" alt="image-20211117151858614"></p><h2 id="泛化误差分析"><a href="#泛化误差分析" class="headerlink" title="泛化误差分析"></a>泛化误差分析</h2><p>假设数据集上需要预测的样本为Y，特征为X，潜在模型为 Y&#x3D;f(X)+ε<em>Y</em>&#x3D;<em>f</em>(<em>X</em>)+<em>ε</em>，其中ε<em>∼</em>N*(0,<em>σε</em>)是噪声, 估计的模型为f*^(<em>X</em>).</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117152159573.png" alt="image-20211117152159573"></p><p><strong>偏差</strong>(bias)反映了模型在样本上的期望输出与真实标记之间的差距，即模型本身的精准度，反应的是模型本身的拟合能力</p><p><strong>方差</strong>(variance)反应了模型在不同训练数据集下学得得函数得输出与期望输出之间的误差，即模型得稳定性，反应的是模型的波动情况</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117152948446.png" alt="image-20211117152948446"></p><p>欠拟合：高偏差低方差</p><p>​寻找更好的特征，提升对数据的刻画额能力</p><p>​增加特征数量</p><p>​重新选择更加复杂的模型‘</p><p>过拟合：低偏差高方差</p><p>​增加训练样本数量</p><p>​减少特征维数，高维空间密度小</p><p>​加入正则化项，使得模型更加平滑</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117153404834.png" alt="image-20211117153404834"></p><h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>基本思路：将训练集划分为K份，每次采用其中K-1份作为训练集，另外一份作为验证集，在训练集上学得函数后，然后在验证集上计算误差&#x3D;&#x3D;&#x3D;K折交叉验证</p><p>​K折交叉重复多次，每次重复中产生不同的分割</p><p>​留一交叉验证(Leave-One-Out)</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117153808061.png" alt="image-20211117153808061"></p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211117160039990.png" alt="image-20211117160039990"></p><h1 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h1><p>​1.数据集有标记(答案)</p><p>​2.数据集通常扩展为(<em>xi</em>,<em>yi</em>)其中𝑦_𝑖∈Y是 <em>xi</em> 的标记，Y是所有标记的集合，称为“标记空间”或“输出空间”</p><p>​3.监督学习的任务是训练出一个模型用于预测y的取值，根据D &#x3D; {(<em>x</em>1,<em>y</em>1),(<em>x</em>2,<em>y</em>2),⋯,(<em>xn</em>,<em>yn</em>)}，训练出函数f，使得<em>f</em>(<em>x</em>)≅<em>y</em></p><p>​4.若预测的值是离散值，如年龄，此类学习任务称为“分类”</p><p>​5.若预测的值是连续值，如房价，此类学习任务称为“回归”</p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>​线性回归是在样本属性和标签中找到一个线性关系的方法，根据训练数据找到一个线性模型，使得模型产生的预测值与样本标标签的差距最小，若用<img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118093904846.png" alt="image-20211118093904846"></p><p>表示第K个样本的第I个属性则线性模型一般形式为：</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118094041696.png" alt="image-20211118094041696"></p><p>线性回归学习的对象就是权重向量w和偏置向量b，如果用最小均方误差来衡量预测值与样本标签的差距，那么线性回归学习的目标可以表示为：</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118094710976.png" alt="image-20211118094710976"></p><h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>逻辑回归是利用𝑠𝑖𝑔𝑚𝑜𝑖𝑑函数，将线性回归产生的预测值压缩到0和1之间，此时将y视作样本为正例的可能性，即</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118095202775.png" alt="image-20211118095202775"></p><p>注意:逻辑回归本质上属于分类算法，sigmoid函数的具体表达形式：<img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118095413748.png" alt="image-20211118095413748"></p><h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>支持向量机是由监督学习中最具影响的力方法之一是基于线性判别函数的一种模型。</p><p>SVM基本思想：对于线性可分得数据，能将训练样本划分开的超平面有很多，于是我们寻找“位于两类训练样本中心的超平面”，即margin最大化，从直观上看，这种划分训练样本局部扰动的承受行最好，事实上，这种划分的性能也表现较好。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118144603874.png" alt="image-20211118144603874"></p><p>下面我们以<strong>线性分类</strong>为例：二类可分数据集<em>D</em>&#x3D;{(<em>x</em>1,<em>y</em>1),(<em>x</em>2,<em>y</em>2),⋯,(<em>xn</em>,<em>yn</em>)}，其中y &#x3D; 1 和 y &#x3D; -1分别表示两类样本定义分类的超平面<em>f</em>(<em>x</em>)&#x3D;<em>w<strong>T</strong>x</em>+<em>b</em>（决策边界 decision boundary) ，<strong>最合适</strong>的分类标准就是使得超平面距离两边数据的间隔最大</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118145009222.png" alt="image-20211118145009222"></p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118145050131.png" alt="image-20211118145050131"></p><p>通常方便优化，我们选择加强约束条件<img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118145130389.png" alt="image-20211118145130389"></p><p>那么原问题可以近似为：</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118145157148.png" alt="image-20211118145157148"></p><p>对于线性不可分数据集，我们可以做下面的操作</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211118145313473.png" alt="image-20211118145313473"></p><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>决策树是一种基于树结构进行决策的机器学习方法，这恰是人类面临决策时一种很自然的处理机制</p><p>​1.在这些树的结构里，叶子节点给出的类标而内部节点代表某个属性；</p><p>​2.例如：银行在面对是否借贷给客户的问题时，通常会进行一系列的决策：银行会首先判断客户的信贷声誉是否良好？良好的话，在判断客户是否有稳定的工作？不良的话可能直接拒绝，也可能判断客户是否有可抵押物？····这种思考的过程便是决策树生成的过程。</p><p>决策树的生成过程中，最重要的因素便是根节点的选择，即选择哪种特征最为决策因素：ID3算法使用信息增益作为准则</p><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><h4 id="集成学习-Ensemblelearning"><a href="#集成学习-Ensemblelearning" class="headerlink" title="集成学习(Ensemblelearning)"></a>集成学习(Ensemblelearning)</h4><p>​1.组合多个弱监督模型以期望得到一个更好更全面的强监督学习，集成学习潜在的思想时即便某一个弱分类器得到了错误的预测，其他的前分类器也可以将错误纠正回来。</p><p>​随机森林随机的方式建立起一颗颗决策树组成一个森林，其中每棵决策树之间没有关联，当有一个新的样本输入时，就让每棵树独立的做出判断，按照多数原则决定该样本的分类结果。</p><p>​随机森林构建的基本步骤</p><p>​1.随机有放回的从训练集中抽取m个训练样本，训练集<em>Dt</em>.</p><p>​2.从<em>Dt</em>.对应的特征属性中随机选择部分特征，构建决策树</p><p>​3.重复上述步骤构建多个决策树</p><h4 id="预测步骤"><a href="#预测步骤" class="headerlink" title="预测步骤"></a>预测步骤</h4><p>​1.向建立好的随机森林中输入一个新样本</p><p>​2.随机森林中每棵决策树都独立的做出判断</p><p>​3.将得到票数最多的分类结果作为该样本的最终类别</p><h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h1><p>​1.数据集没有标记信息（自学）</p><p>​2.聚类：我们可以使用无监督学习来预测各样本之间的关联度，把关联度大的样本划分为同一类，关联度小的样本划分为不同类，这便是“聚类”</p><p>​3.降维：我们也可以使用无监督学习处理数据，把维度较高，计算复杂的数据，转化为维度低，易处理，且蕴含信息不丢失或较少丢失的数据，这便是“降维”</p><h4 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h4><p>聚类的目的是将数据分类多个类别，在同一个类内，对象(实体)之间具有较高的相似性，在不同类内，对象之间具有较大的差异。</p><p>对一批没有类别标签的样本集，按照样本之间的相似性程度分类，相似的归为一类，不相似的归为其他类，这种分类称为聚类分析，也称为无监督分类</p><p>常见的方法有K-Means聚类、均值漂移聚类、基于密度的聚类等</p><p><strong>K-means</strong>聚类是一个反复迭代的过程，算法分为四个步骤：</p><p>​1.选取数据空间中的K个对象作为初始中心，每个对象代表一个聚类中心；</p><p>​2.对于样本中的数据对象，根据他们与这些聚类中心的欧式距离，按距离最近的准则将他们分到距离他们最近的聚类中心（最相似）所对应的类</p><p>​3.更新聚类中心，将每个类别中所有对象所对应的均值作为该类别的聚类中心，计算目标函数的值。</p><p>​4.判断聚类中心和目标函数的值是否发生改变，若不变，则输出结果，若改变，则返回2</p><h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><p>降维的目的就是将原始样本数据维度d降到一个更小的数m，且尽量使得样本蕴含信息损失最小，或还原数据时产生的误差最小，比如主成分分析法···</p><p>降维的优势：</p><p>​1.数据子在低纬度下更容易处理，更容易使用</p><p>​2.相关特征，特别是重要特征更能在数据中明确的显示出来</p><p>​3.如果只有二维或者三维的话，能够进行可视化展示；</p><p>​4.去除数据噪声，降低算法开销等</p><h1 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h1><p>​1.神经源模型</p><p>​2.感知器，多层感知器</p><p>​3.BP算法</p><p>​4.前馈神经网络</p><h2 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h2><p>神经元(M-P)</p><p>1943 年，美国神经生理学家沃伦·麦卡洛克( Warren McCulloch ) 和数学家沃尔特 ·皮茨(Walter Pitts )对生物神经元进行建模，首次提出了一种形式神经元模型，并命名为McCulloch-Pitts模型，即后 来广为人知的M-P模型。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211119084055045.png" alt="image-20211119084055045"></p><p>在M-P模型中神经元接受其他n个神经元的输入信号（0或1），这些输入信号经过权重加权并求和，将求和结果与阈值（threshold) <em>θ</em> 比较，然后经过激活函数处理，得到神经元的输出</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211119085636193.png" alt="image-20211119085636193"></p><p>M-P模型可以表示多种逻辑运算，如取反运算，逻辑或，逻辑与</p><p>取返运算可以用单输入单输出模型表示，即如果输入为0则输出为1，如果输入为1，则输出为0，由M-P模型的运算规则可得w &#x3D; -2，<em>θ</em>&#x3D;−1.</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211119090021286.png" alt="image-20211119090021286"></p><p>逻辑或与逻辑与运算可以用双输入单输出模型表示，以逻辑与运算为例<em>w</em>1&#x3D;1，<em>w</em>2&#x3D;1,<em>θ</em>&#x3D;1.5.<img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211119090144242.png" alt="image-20211119090144242"></p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>人工神经网络由神经元模型构成，这种由许多神经元组成的信息处理网络具有并行分布结构。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211119090246788.png" alt="image-20211119090246788"></p><p>其中圆形节点表示一个神经元，方形节点表示一组神经元。</p><h2 id="感知器"><a href="#感知器" class="headerlink" title="感知器"></a>感知器</h2><h4 id="单层感知器"><a href="#单层感知器" class="headerlink" title="单层感知器"></a>单层感知器</h4><p>​1958 年，罗森布拉特( Roseblatt )提出了感知器，与M-P模型需要人为的确定参数不同，感知器能通过训练自动确定参数，感知器能够通过训练自动确定参数，训练方式为有监督学习，即许需要设定训练样本和期望输出，然后调整实际输出和期望输出之差的方式</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120082340144.png" alt="image-20211120082340144"></p><p>其中，<em>α</em> 是学习率，<em>r</em>和 <em>y</em> 分别是期望输出和实际输出。</p><p>感知器权重体调节的基本思路：</p><p>​实际输出y与期望输出r相等时，w 和 θ 不变</p><p>​实际输出y与期望输出r不相等时，调整w和θ的值</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120083825204.png" alt="image-20211120083825204"></p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120083835325.png" alt="image-20211120083835325"></p><p>下面给出感知器模型的训练过程</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120083903156.png" alt="image-20211120083903156"></p><h4 id="多层感知器"><a href="#多层感知器" class="headerlink" title="多层感知器"></a>多层感知器</h4><p>单层感知器只能解决线性可分问题，而不能解决线性不可分问题；为了解决线性不可分问题，我们需要使用多层感知器。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120084052586.png" alt="image-20211120084052586"></p><p>多层感知器指的是由多层结构的感知器递阶组成的输入值向前传播的网络，也被称为前馈网络或者正向传播网络</p><p>​以三层结构的多层感知器为例，他由输入层，中间层及输出层组成</p><p>​1.与M-P模型相同，中间层的感知器通过权重与输入层的个单元相连接，通过阈值函数计算中间层各单位的输出值</p><p>​2.中间层与输出层之间同样是通过权重相连接</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120084716924.png" alt="image-20211120084716924"></p><h2 id="BP算法"><a href="#BP算法" class="headerlink" title="BP算法"></a>BP算法</h2><p>多层感知器的训练使用误差反向传播算法(Error Back Propagation)，即BP算法。</p><h4 id="BP算法的基本过程"><a href="#BP算法的基本过程" class="headerlink" title="BP算法的基本过程"></a>BP算法的基本过程</h4><p>​1.前向传播计算：由输入层经过隐含层向输出层的计算网络输出</p><p>​2.误差反向逐层传递:网络的期望输出与实际输出之差的误差信号由输出层经过隐含层逐层向输入层传递</p><p>​3.由“前向传播计算”与“误差反向逐层传递”的反复进行的网络训练 过程</p><p>BP算法就是通过比较实际输出和期望输出得到误差信号，把误差信 号从输出层逐层向前传播得到各层的误差信号，再通过调整各层的连接权重以减小误差。权重的调整主要使用梯度下降法：</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211120085409192.png" alt="image-20211120085409192"></p><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>通过误差反向传播算法调整多层感知器的连接权重时，一个瓶颈问题就是<strong>激活函数</strong>：</p><h4 id="优化问腿"><a href="#优化问腿" class="headerlink" title="优化问腿"></a>优化问腿</h4><p>难点：</p><p>​1.参数过多，影响训练</p><p>​2.非凸优化问题：即存在局部最优而非全局最优解，影响迭代</p><p>​3.梯度消失问题，下层参数比较难调</p><p>​4.参数解释起来比较困难</p><p>需求：</p><p>​1.计算资源要大</p><p>​2.非凸优化问题，下层参数比较偏难调</p><p>​3.参数解释起来比较困难</p><h4 id="非凸优化问题"><a href="#非凸优化问题" class="headerlink" title="非凸优化问题"></a>非凸优化问题</h4><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211123140602258.png" alt="image-20211123140602258"></p><h4 id="梯度消失问题"><a href="#梯度消失问题" class="headerlink" title="梯度消失问题"></a>梯度消失问题</h4><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211123140620554.png" alt="image-20211123140620554"></p><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p>卷积神经网络</p><ol><li>卷积</li><li>CNN基本原理</li><li>经典CNN</li><li>CNN主要应用</li></ol><p>全连接神经网络权重矩阵参数非常的多。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211124081137691.png" alt="image-20211124081137691"></p><p>而往往自然图像中的物体都具有局部不变性特征，即尺度缩放，平移，旋转等操作不影响其语义信息，但是全连接前馈网络很难提取这些局部不变特征性，这变就需要接下来的卷积神经网络（Convolutional Neural Networks，CNN）</p><p>卷积神经网络也是一种前馈神经网络，是受到生物学上感受野（感受野主要是指听觉系统，本体感觉系统和视觉系统中神经元的一些性质）的机制而提出的（在视觉神经神经系统中，一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够刺激活该神经元）</p><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>卷积：(<em>f</em>*<em>g</em>)(<em>n</em>)成为 f*和 g的卷积，连续卷积和离散卷积可以表达为如下形式：</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211124082213312.png" alt="image-20211124082213312"></p><p>卷积有很多应用，经常用于处理一个输入，通过系统产生一个适应需求的输出。</p><p>​1.统计学中加权平均法</p><p>​2.概率论中两个独立变量之和概率密度的计算</p><p>​3.信号处理中的线性系统</p><p>​4.物理学的线性系统</p><p>​5.图像处理中的应用(卷积神经网络)</p><p>卷积经常用在信号处理中，用于计算机信号延迟积累</p><p>在图像处理中，图像是以二维矩阵的形式输出到神经网络中，因此我们需要二维卷积。</p><p>典型的卷积层为3维结构</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211124083405497.png" alt="image-20211124083405497"></p><h2 id="卷积神经网络基本原理"><a href="#卷积神经网络基本原理" class="headerlink" title="卷积神经网络基本原理"></a>卷积神经网络基本原理</h2><p>卷积神经网络的基本结构大致包括：卷积层，激活函数，池化层，全连接层，输出层。</p><h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>二维卷积运算：给定二维的图像<em>I</em>作为输入，二维卷积核<em>K</em>，卷积运算可表示为 S(i, j)&#x3D;(I * K)(i, j)&#x3D;\sum_{m} \sum_{n} I(i-m, j-n) K(m, n)<em>S</em>(<em>i</em>,<em>j</em>)&#x3D;(<em>I</em>∗<em>K</em>)(<em>i</em>,<em>j</em>)&#x3D;∑<em>m</em>∑<em>n**I</em>(<em>i</em>−<em>m</em>,<em>j</em>−<em>n</em>)<em>K</em>(<em>m</em>,<em>n</em>)，卷积核需要进行上下翻转和左右反转</p><h2 id="激活函数-1"><a href="#激活函数-1" class="headerlink" title="激活函数"></a>激活函数</h2><p>激活函数是用来加入非线性因素，提高网络表达能力，卷积神经网络中最常用的是ReLU，Sigmoid使用较少。</p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211127200813287.png" alt="image-20211127200813287"></p><p><img src="C:\Users\JINHE1997\AppData\Roaming\Typora\typora-user-images\image-20211127200824747.png" alt="image-20211127200824747"></p><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化操作使用某位置相邻输出的总体统计特征作为该位置 的输出，常用最大池化**(max-pooling)<strong>和均值池化</strong>(average- pooling)**。</p><p>池化层不包含需要训练学习的参数，仅需指定池化操作的核大小、操作步幅以及池化类型。</p><h2 id="卷积神经网络的训练"><a href="#卷积神经网络的训练" class="headerlink" title="卷积神经网络的训练"></a>卷积神经网络的训练</h2><p>Step 1：用随机数初始化所有的卷积核和参数&#x2F;权重</p><p>Step 2：将训练图片作为输入，执行前向步骤(卷积， ReLU，池化以及全连接层的前向传播)并计算每个类别的对应输出概率。</p><p>Step 3：计算输出层的总误差</p><p>Step 4：反向传播算法计算误差相对于所有权重的梯度，并用梯度下降法更新所有的卷积核和参数&#x2F;权重的值，以使输出误差最小化</p><p>注：卷积核个数、卷积核尺寸、网络架构这些参数，是在 Step 1 之前就已经固定的，且不会在训练过程中改变——只有卷 积核矩阵和神经元权重会更新。</p><h2 id="景点卷积神经网络"><a href="#景点卷积神经网络" class="headerlink" title="景点卷积神经网络"></a>景点卷积神经网络</h2><h3 id="1-LeNet-5"><a href="#1-LeNet-5" class="headerlink" title="1. LeNet-5"></a>1. LeNet-5</h3><p>LeNet-5由LeCun等人提出于1998年提出，主要进行手写数字识别和英文字母识别。经典的卷积神经网络，LeNet虽小，各模块齐全，是学习 CNN的基础。</p><h3 id="2-AlexNet"><a href="#2-AlexNet" class="headerlink" title="2. AlexNet"></a>2. AlexNet</h3><p>AlexNet由Hinton的学生Alex Krizhevsky于2012年提出，获得ImageNet LSVRC-2012(物体识别挑战赛)的冠军，1000个类别120万幅高清图像（Error: 26.2%(2011) →15.3%(2012)），通过AlexNet确定了CNN在计算机视觉领域的王者地位。</p><h3 id="3-VGGNet"><a href="#3-VGGNet" class="headerlink" title="3. VGGNet"></a>3. VGGNet</h3><h3 id="4-Inception-Net"><a href="#4-Inception-Net" class="headerlink" title="4. Inception Net"></a>4. Inception Net</h3><h3 id="5-ResNet"><a href="#5-ResNet" class="headerlink" title="5. ResNet"></a>5. ResNet</h3><h2 id="主要应用-1"><a href="#主要应用-1" class="headerlink" title="主要应用"></a>主要应用</h2><p><strong>图像处理领域主要应用</strong></p><ul><li>图像分类(物体识别)：整幅图像的分类或识别</li><li>物体检测：检测图像中物体的位置进而识别物体</li><li>图像分割：对图像中的特定物体按边缘进行分割</li><li>图像回归：预测图像中物体组成部分的坐标</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
